# trainer/default
# * [ ] Group loss_fn

# == Default List ==
defaults:
    - optimizer: adam
    - lr_skd: cos

# == Trainer Core ==
device: "cuda:0"
epochs: 80
loss_fn:
    name: "ml1"
    rescale: False
# Model checkpoint
model_ckpt:
    ckpt_metric: mmae
    ckpt_mode: min
    best_ckpt_mid: last
# Early stopping
es:
    patience: 0
    mode: null

dataloader:
    batch_size: 128
    shuffle: True
    num_workers: 4
    pin_memory: False
    drop_last: False

evaluator:
    eval_metrics:
        - mmae

grad_accum_steps: 1
step_per_batch: True
use_amp: null

# == Debug Option ==
# If True, `_train_epoch` stops after one batch
one_batch_only: False
